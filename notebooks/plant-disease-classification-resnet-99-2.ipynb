{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.059875,
     "end_time": "2020-12-15T06:52:44.191791",
     "exception": false,
     "start_time": "2020-12-15T06:52:44.131916",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  PLANT DISEASE CLASSIFICATION USING RESNET-9 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 1.704433,
     "end_time": "2020-12-15T06:52:56.166377",
     "exception": false,
     "start_time": "2020-12-15T06:52:54.461944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os                       # for working with files\n",
    "import numpy as np              # for numerical computationss\n",
    "import pandas as pd             # for working with dataframes\n",
    "import torch                    # Pytorch module \n",
    "import matplotlib.pyplot as plt # for plotting informations on graph and images using tensors\n",
    "import torch.nn as nn           # for creating  neural networks\n",
    "from torch.utils.data import DataLoader # for dataloaders \n",
    "from PIL import Image           # for checking images\n",
    "import torch.nn.functional as F # for functions for calculating loss\n",
    "import torchvision.transforms as transforms   # for transforming images into tensors \n",
    "from torchvision.utils import make_grid       # for data checking\n",
    "from torchvision.datasets import ImageFolder  # for working with classes and images\n",
    "from torchsummary import summary              # for getting the summary of our model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.05825,
     "end_time": "2020-12-15T06:52:56.400725",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.342475",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Loading the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.522416Z",
     "iopub.status.busy": "2020-12-15T06:52:56.521802Z",
     "iopub.status.idle": "2020-12-15T06:52:56.536807Z",
     "shell.execute_reply": "2020-12-15T06:52:56.536213Z"
    },
    "papermill": {
     "duration": 0.07813,
     "end_time": "2020-12-15T06:52:56.536899",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.458769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"Data-raw/archive/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "train_dir = data_dir + \"/train\"\n",
    "valid_dir = data_dir + \"/valid\"\n",
    "diseases = os.listdir(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:52:56.922040Z",
     "iopub.status.busy": "2020-12-15T06:52:56.921156Z",
     "iopub.status.idle": "2020-12-15T06:52:56.924421Z",
     "shell.execute_reply": "2020-12-15T06:52:56.923843Z"
    },
    "papermill": {
     "duration": 0.071422,
     "end_time": "2020-12-15T06:52:56.924536",
     "exception": false,
     "start_time": "2020-12-15T06:52:56.853114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plants = []\n",
    "NumberOfDiseases = 0\n",
    "for plant in diseases:\n",
    "    if plant.split('___')[0] not in plants:\n",
    "        plants.append(plant.split('___')[0])\n",
    "    if plant.split('___')[1] != 'healthy':\n",
    "        NumberOfDiseases += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:53:05.548188Z",
     "iopub.status.busy": "2020-12-15T06:53:05.547365Z",
     "iopub.status.idle": "2020-12-15T06:54:23.286526Z",
     "shell.execute_reply": "2020-12-15T06:54:23.285629Z"
    },
    "papermill": {
     "duration": 77.805914,
     "end_time": "2020-12-15T06:54:23.286647",
     "exception": false,
     "start_time": "2020-12-15T06:53:05.480733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# datasets for validation and training\n",
    "train = ImageFolder(train_dir, transform=transforms.ToTensor())\n",
    "valid = ImageFolder(valid_dir, transform=transforms.ToTensor()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.063883,
     "end_time": "2020-12-15T06:54:23.415740",
     "exception": false,
     "start_time": "2020-12-15T06:54:23.351857",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`torchvision.datasets` is a class which helps in loading all common and famous datasets. It also helps in loading custom datasets. I have used subclass `torchvision.datasets.ImageFolder` which helps in loading the image data when the data is arranged in this way:\n",
    "\n",
    "----------------\n",
    "root/dog/xxx.png\n",
    "\n",
    "root/dog/xxy.png\n",
    "\n",
    "root/dog/xxz.png\n",
    "\n",
    "<br>\n",
    "\n",
    "root/cat/123.png\n",
    "\n",
    "root/cat/nsdf3.png\n",
    "\n",
    "root/cat/asd932_.png\n",
    "\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:24.296508Z",
     "iopub.status.busy": "2020-12-15T06:54:24.295743Z",
     "iopub.status.idle": "2020-12-15T06:54:24.298712Z",
     "shell.execute_reply": "2020-12-15T06:54:24.298233Z"
    },
    "papermill": {
     "duration": 0.073411,
     "end_time": "2020-12-15T06:54:24.298812",
     "exception": false,
     "start_time": "2020-12-15T06:54:24.225401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for checking some images from training dataset\n",
    "def show_image(image, label):\n",
    "    print(\"Label :\" + train.classes[label] + \"(\" + str(label) + \")\")\n",
    "    plt.imshow(image.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:25.648270Z",
     "iopub.status.busy": "2020-12-15T06:54:25.647636Z",
     "iopub.status.idle": "2020-12-15T06:54:25.655836Z",
     "shell.execute_reply": "2020-12-15T06:54:25.655136Z"
    },
    "papermill": {
     "duration": 0.093711,
     "end_time": "2020-12-15T06:54:25.655943",
     "exception": false,
     "start_time": "2020-12-15T06:54:25.562232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x21d7f8c6d30>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the seed value\n",
    "random_seed = 7\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:25.813296Z",
     "iopub.status.busy": "2020-12-15T06:54:25.812568Z",
     "iopub.status.idle": "2020-12-15T06:54:25.815698Z",
     "shell.execute_reply": "2020-12-15T06:54:25.815224Z"
    },
    "papermill": {
     "duration": 0.083405,
     "end_time": "2020-12-15T06:54:25.815796",
     "exception": false,
     "start_time": "2020-12-15T06:54:25.732391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setting the batch size\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:26.144973Z",
     "iopub.status.busy": "2020-12-15T06:54:26.143969Z",
     "iopub.status.idle": "2020-12-15T06:54:26.146484Z",
     "shell.execute_reply": "2020-12-15T06:54:26.147104Z"
    },
    "papermill": {
     "duration": 0.097126,
     "end_time": "2020-12-15T06:54:26.147260",
     "exception": false,
     "start_time": "2020-12-15T06:54:26.050134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataLoaders for training and validation\n",
    "train_dl = DataLoader(train, batch_size, shuffle=True, num_workers=2, pin_memory=True)\n",
    "valid_dl = DataLoader(valid, batch_size, num_workers=2, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:26.459616Z",
     "iopub.status.busy": "2020-12-15T06:54:26.458860Z",
     "iopub.status.idle": "2020-12-15T06:54:26.461331Z",
     "shell.execute_reply": "2020-12-15T06:54:26.461924Z"
    },
    "papermill": {
     "duration": 0.08434,
     "end_time": "2020-12-15T06:54:26.462045",
     "exception": false,
     "start_time": "2020-12-15T06:54:26.377705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to show a batch of training instances\n",
    "def show_batch(data):\n",
    "    for images, labels in data:\n",
    "        fig, ax = plt.subplots(figsize=(30, 30))\n",
    "        ax.set_xticks([]); ax.set_yticks([])\n",
    "        ax.imshow(make_grid(images, nrow=8).permute(1, 2, 0))\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.148317,
     "end_time": "2020-12-15T06:54:33.881587",
     "exception": false,
     "start_time": "2020-12-15T06:54:33.733270",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Modelling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:34.778895Z",
     "iopub.status.busy": "2020-12-15T06:54:34.777939Z",
     "iopub.status.idle": "2020-12-15T06:54:34.780617Z",
     "shell.execute_reply": "2020-12-15T06:54:34.781074Z"
    },
    "papermill": {
     "duration": 0.163682,
     "end_time": "2020-12-15T06:54:34.781228",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.617546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for moving data into GPU (if available)\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available:\n",
    "        return torch.device(\"cuda\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "# for moving data to device (CPU or GPU)\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "# for loading in the device (GPU if available else CPU)\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.150399,
     "end_time": "2020-12-15T06:54:35.079034",
     "exception": false,
     "start_time": "2020-12-15T06:54:34.928635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Checking the device we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:35.382785Z",
     "iopub.status.busy": "2020-12-15T06:54:35.381977Z",
     "iopub.status.idle": "2020-12-15T06:54:35.385943Z",
     "shell.execute_reply": "2020-12-15T06:54:35.385339Z"
    },
    "papermill": {
     "duration": 0.159177,
     "end_time": "2020-12-15T06:54:35.386046",
     "exception": false,
     "start_time": "2020-12-15T06:54:35.226869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.147431,
     "end_time": "2020-12-15T06:54:36.291718",
     "exception": false,
     "start_time": "2020-12-15T06:54:36.144287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Building the model architecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.161795,
     "end_time": "2020-12-15T06:54:36.602798",
     "exception": false,
     "start_time": "2020-12-15T06:54:36.441003",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "*We are going to use **ResNet**, which have been one of the major breakthrough in computer vision since they were introduced in 2015.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.147768,
     "end_time": "2020-12-15T06:54:37.826313",
     "exception": false,
     "start_time": "2020-12-15T06:54:37.678545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Residual Block code implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:38.140386Z",
     "iopub.status.busy": "2020-12-15T06:54:38.139498Z",
     "iopub.status.idle": "2020-12-15T06:54:38.142557Z",
     "shell.execute_reply": "2020-12-15T06:54:38.142037Z"
    },
    "papermill": {
     "duration": 0.167702,
     "end_time": "2020-12-15T06:54:38.142655",
     "exception": false,
     "start_time": "2020-12-15T06:54:37.974953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleResidualBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(in_channels=3, out_channels=3, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        return self.relu2(out) + x # ReLU can be applied before or after adding the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:39.367899Z",
     "iopub.status.busy": "2020-12-15T06:54:39.362848Z",
     "iopub.status.idle": "2020-12-15T06:54:39.389963Z",
     "shell.execute_reply": "2020-12-15T06:54:39.391114Z"
    },
    "papermill": {
     "duration": 0.532121,
     "end_time": "2020-12-15T06:54:39.391404",
     "exception": false,
     "start_time": "2020-12-15T06:54:38.859283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for calculating the accuracy\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "\n",
    "# base class for the model\n",
    "class ImageClassificationBase(nn.Module):\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                  # Generate predictions\n",
    "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch\n",
    "        out = self(images)                   # Generate prediction\n",
    "        loss = F.cross_entropy(out, labels)  # Calculate loss\n",
    "        acc = accuracy(out, labels)          # Calculate accuracy\n",
    "        return {\"val_loss\": loss.detach(), \"val_accuracy\": acc}\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x[\"val_loss\"] for x in outputs]\n",
    "        batch_accuracy = [x[\"val_accuracy\"] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()       # Combine loss  \n",
    "        epoch_accuracy = torch.stack(batch_accuracy).mean()\n",
    "        return {\"val_loss\": epoch_loss, \"val_accuracy\": epoch_accuracy} # Combine accuracies\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], last_lr: {:.5f}, train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n",
    "            epoch, result['lrs'][-1], result['train_loss'], result['val_loss'], result['val_accuracy']))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.203515,
     "end_time": "2020-12-15T06:54:39.894829",
     "exception": false,
     "start_time": "2020-12-15T06:54:39.691314",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##  Defining the final architecture of our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:40.222910Z",
     "iopub.status.busy": "2020-12-15T06:54:40.222083Z",
     "iopub.status.idle": "2020-12-15T06:54:40.226361Z",
     "shell.execute_reply": "2020-12-15T06:54:40.225720Z"
    },
    "papermill": {
     "duration": 0.17469,
     "end_time": "2020-12-15T06:54:40.226460",
     "exception": false,
     "start_time": "2020-12-15T06:54:40.051770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Architecture for training\n",
    "\n",
    "# convolution block with BatchNormalization\n",
    "def ConvBlock(in_channels, out_channels, pool=False):\n",
    "    layers = [nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "             nn.BatchNorm2d(out_channels),\n",
    "             nn.ReLU(inplace=True)]\n",
    "    if pool:\n",
    "        layers.append(nn.MaxPool2d(4))\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "# resnet architecture \n",
    "class ResNet9(ImageClassificationBase):\n",
    "    def __init__(self, in_channels, num_diseases):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = ConvBlock(in_channels, 64)\n",
    "        self.conv2 = ConvBlock(64, 128, pool=True) # out_dim : 128 x 64 x 64 \n",
    "        self.res1 = nn.Sequential(ConvBlock(128, 128), ConvBlock(128, 128))\n",
    "        \n",
    "        self.conv3 = ConvBlock(128, 256, pool=True) # out_dim : 256 x 16 x 16\n",
    "        self.conv4 = ConvBlock(256, 512, pool=True) # out_dim : 512 x 4 x 44\n",
    "        self.res2 = nn.Sequential(ConvBlock(512, 512), ConvBlock(512, 512))\n",
    "        \n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                       nn.Flatten(),\n",
    "                                       nn.Linear(512, num_diseases))\n",
    "        \n",
    "    def forward(self, xb): # xb is the loaded batch\n",
    "        out = self.conv1(xb)\n",
    "        out = self.conv2(out)\n",
    "        out = self.res1(out) + out\n",
    "        out = self.conv3(out)\n",
    "        out = self.conv4(out)\n",
    "        out = self.res2(out) + out\n",
    "        out = self.classifier(out)\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.149615,
     "end_time": "2020-12-15T06:54:40.527855",
     "exception": false,
     "start_time": "2020-12-15T06:54:40.378240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now, we define a model object and transfer it into the device with which we are working..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:40.847626Z",
     "iopub.status.busy": "2020-12-15T06:54:40.846635Z",
     "iopub.status.idle": "2020-12-15T06:54:40.918385Z",
     "shell.execute_reply": "2020-12-15T06:54:40.918921Z"
    },
    "papermill": {
     "duration": 0.237477,
     "end_time": "2020-12-15T06:54:40.919048",
     "exception": false,
     "start_time": "2020-12-15T06:54:40.681571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet9(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (conv2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res1): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (conv4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (res2): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=512, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the model and moving it to the GPU\n",
    "model = ResNet9(3, len(train.classes))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.14664,
     "end_time": "2020-12-15T06:54:42.545891",
     "exception": false,
     "start_time": "2020-12-15T06:54:42.399251",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#  Training the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:43.464522Z",
     "iopub.status.busy": "2020-12-15T06:54:43.463494Z",
     "iopub.status.idle": "2020-12-15T06:54:43.466732Z",
     "shell.execute_reply": "2020-12-15T06:54:43.466153Z"
    },
    "papermill": {
     "duration": 0.169191,
     "end_time": "2020-12-15T06:54:43.466833",
     "exception": false,
     "start_time": "2020-12-15T06:54:43.297642",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for training\n",
    "@torch.no_grad()\n",
    "def evaluate(model, val_loader):\n",
    "    model.eval()\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "    \n",
    "\n",
    "def fit_OneCycle(epochs, max_lr, model, train_loader, val_loader, weight_decay=0,\n",
    "                grad_clip=None, opt_func=torch.optim.SGD):\n",
    "    torch.cuda.empty_cache()\n",
    "    history = []\n",
    "    \n",
    "    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n",
    "    # scheduler for one cycle learniing rate\n",
    "    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        lrs = []\n",
    "        for batch in train_loader:\n",
    "            loss = model.training_step(batch)\n",
    "            train_losses.append(loss)\n",
    "            loss.backward()\n",
    "            \n",
    "            # gradient clipping\n",
    "            if grad_clip: \n",
    "                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n",
    "                \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # recording and updating learning rates\n",
    "            lrs.append(get_lr(optimizer))\n",
    "            sched.step()\n",
    "            \n",
    "    \n",
    "        # validation\n",
    "        result = evaluate(model, val_loader)\n",
    "        result['train_loss'] = torch.stack(train_losses).mean().item()\n",
    "        result['lrs'] = lrs\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "        \n",
    "    return history\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.148385,
     "end_time": "2020-12-15T06:54:43.768339",
     "exception": false,
     "start_time": "2020-12-15T06:54:43.619954",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check our validation loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:54:44.229384Z",
     "iopub.status.busy": "2020-12-15T06:54:44.228659Z",
     "iopub.status.idle": "2020-12-15T06:56:16.949501Z",
     "shell.execute_reply": "2020-12-15T06:56:16.948857Z"
    },
    "papermill": {
     "duration": 93.028639,
     "end_time": "2020-12-15T06:56:16.949629",
     "exception": false,
     "start_time": "2020-12-15T06:54:43.920990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 229, in __getitem__\n    sample = self.loader(path)\n             ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 268, in default_loader\n    return pil_loader(path)\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 246, in pil_loader\n    with open(path, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'Data-raw/archive/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\\\\Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\\\\00e00912-bf75-4cf8-8b7d-ad64b73bea5f___Mt.N.V_HL 6067_new30degFlipLR.JPG'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#%%time\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m [evaluate(model, valid_dl)]\n\u001b[0;32m      3\u001b[0m history\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[39mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 115\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(model, val_loader)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(model, val_loader):\n\u001b[0;32m      4\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> 5\u001b[0m     outputs \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39;49mvalidation_step(batch) \u001b[39mfor\u001b[39;49;00m batch \u001b[39min\u001b[39;49;00m val_loader]\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "Cell \u001b[1;32mIn[17], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mevaluate\u001b[39m(model, val_loader):\n\u001b[0;32m      4\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m----> 5\u001b[0m     outputs \u001b[39m=\u001b[39m [model\u001b[39m.\u001b[39mvalidation_step(batch) \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m val_loader]\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39mvalidation_epoch_end(outputs)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 1.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 229, in __getitem__\n    sample = self.loader(path)\n             ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 268, in default_loader\n    return pil_loader(path)\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 246, in pil_loader\n    with open(path, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'Data-raw/archive/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/valid\\\\Grape___Leaf_blight_(Isariopsis_Leaf_Spot)\\\\00e00912-bf75-4cf8-8b7d-ad64b73bea5f___Mt.N.V_HL 6067_new30degFlipLR.JPG'\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "history = [evaluate(model, valid_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:56:17.600661Z",
     "iopub.status.busy": "2020-12-15T06:56:17.598919Z",
     "iopub.status.idle": "2020-12-15T06:56:17.601325Z",
     "shell.execute_reply": "2020-12-15T06:56:17.601787Z"
    },
    "papermill": {
     "duration": 0.162208,
     "end_time": "2020-12-15T06:56:17.601908",
     "exception": false,
     "start_time": "2020-12-15T06:56:17.439700",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 2\n",
    "max_lr = 0.01\n",
    "grad_clip = 0.1\n",
    "weight_decay = 1e-4\n",
    "opt_func = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.157106,
     "end_time": "2020-12-15T06:56:17.913801",
     "exception": false,
     "start_time": "2020-12-15T06:56:17.756695",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's start training our model ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T06:56:18.447829Z",
     "iopub.status.busy": "2020-12-15T06:56:18.446899Z",
     "iopub.status.idle": "2020-12-15T07:16:12.440007Z",
     "shell.execute_reply": "2020-12-15T07:16:12.440757Z"
    },
    "papermill": {
     "duration": 1194.323015,
     "end_time": "2020-12-15T07:16:12.440924",
     "exception": false,
     "start_time": "2020-12-15T06:56:18.117909",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 229, in __getitem__\n    sample = self.loader(path)\n             ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 268, in default_loader\n    return pil_loader(path)\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 246, in pil_loader\n    with open(path, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'Data-raw/archive/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\\\\Tomato___Spider_mites Two-spotted_spider_mite\\\\0a578317-a98b-4e26-b17b-cd2930330375___Com.G_TgS_FL 0785_180deg.JPG'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn[17], line 29\u001b[0m, in \u001b[0;36mfit_OneCycle\u001b[1;34m(epochs, max_lr, model, train_loader, val_loader, weight_decay, grad_clip, opt_func)\u001b[0m\n\u001b[0;32m     27\u001b[0m train_losses \u001b[39m=\u001b[39m []\n\u001b[0;32m     28\u001b[0m lrs \u001b[39m=\u001b[39m []\n\u001b[1;32m---> 29\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m train_loader:\n\u001b[0;32m     30\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mtraining_step(batch)\n\u001b[0;32m     31\u001b[0m     train_losses\u001b[39m.\u001b[39mappend(loss)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1343\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1344\u001b[0m     \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_task_info[idx]\n\u001b[1;32m-> 1345\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_data(data)\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1369\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_put_index()\n\u001b[0;32m   1370\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[1;32m-> 1371\u001b[0m     data\u001b[39m.\u001b[39;49mreraise()\n\u001b[0;32m   1372\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:644\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    641\u001b[0m     \u001b[39m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[0;32m    642\u001b[0m     \u001b[39m# instantiate since we don't know how to\u001b[39;00m\n\u001b[0;32m    643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 644\u001b[0m \u001b[39mraise\u001b[39;00m exception\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Caught FileNotFoundError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n            ~~~~~~~~~~~~^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 229, in __getitem__\n    sample = self.loader(path)\n             ^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 268, in default_loader\n    return pil_loader(path)\n           ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\vivek\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torchvision\\datasets\\folder.py\", line 246, in pil_loader\n    with open(path, \"rb\") as f:\n         ^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: 'Data-raw/archive/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)/train\\\\Tomato___Spider_mites Two-spotted_spider_mite\\\\0a578317-a98b-4e26-b17b-cd2930330375___Com.G_TgS_FL 0785_180deg.JPG'\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = fit_OneCycle(epochs, max_lr, model, train_dl, valid_dl, \n",
    "                             grad_clip=grad_clip, \n",
    "                             weight_decay=1e-4, \n",
    "                             opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.169551,
     "end_time": "2020-12-15T07:16:13.107269",
     "exception": false,
     "start_time": "2020-12-15T07:16:12.937718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Plotting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.164374,
     "end_time": "2020-12-15T07:16:13.436479",
     "exception": false,
     "start_time": "2020-12-15T07:16:13.272105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Helper functions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:13.764368Z",
     "iopub.status.busy": "2020-12-15T07:16:13.763714Z",
     "iopub.status.idle": "2020-12-15T07:16:13.768095Z",
     "shell.execute_reply": "2020-12-15T07:16:13.767310Z"
    },
    "papermill": {
     "duration": 0.17176,
     "end_time": "2020-12-15T07:16:13.768238",
     "exception": false,
     "start_time": "2020-12-15T07:16:13.596478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_accuracies(history):\n",
    "    accuracies = [x['val_accuracy'] for x in history]\n",
    "    plt.plot(accuracies, '-x')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('Accuracy vs. No. of epochs');\n",
    "\n",
    "def plot_losses(history):\n",
    "    train_losses = [x.get('train_loss') for x in history]\n",
    "    val_losses = [x['val_loss'] for x in history]\n",
    "    plt.plot(train_losses, '-bx')\n",
    "    plt.plot(val_losses, '-rx')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.legend(['Training', 'Validation'])\n",
    "    plt.title('Loss vs. No. of epochs');\n",
    "    \n",
    "def plot_lrs(history):\n",
    "    lrs = np.concatenate([x.get('lrs', []) for x in history])\n",
    "    plt.plot(lrs)\n",
    "    plt.xlabel('Batch no.')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.title('Learning Rate vs. Batch no.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163691,
     "end_time": "2020-12-15T07:16:16.647423",
     "exception": false,
     "start_time": "2020-12-15T07:16:16.483732",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing model on test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:17.486559Z",
     "iopub.status.busy": "2020-12-15T07:16:17.485301Z",
     "iopub.status.idle": "2020-12-15T07:16:17.501849Z",
     "shell.execute_reply": "2020-12-15T07:16:17.503584Z"
    },
    "papermill": {
     "duration": 0.287752,
     "end_time": "2020-12-15T07:16:17.503784",
     "exception": false,
     "start_time": "2020-12-15T07:16:17.216032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dir = \"../input/new-plant-diseases-dataset/test\"\n",
    "test = ImageFolder(test_dir, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:17.927154Z",
     "iopub.status.busy": "2020-12-15T07:16:17.925594Z",
     "iopub.status.idle": "2020-12-15T07:16:17.930241Z",
     "shell.execute_reply": "2020-12-15T07:16:17.930740Z"
    },
    "papermill": {
     "duration": 0.177962,
     "end_time": "2020-12-15T07:16:17.930865",
     "exception": false,
     "start_time": "2020-12-15T07:16:17.752903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AppleCedarRust1.JPG',\n",
       " 'AppleCedarRust2.JPG',\n",
       " 'AppleCedarRust3.JPG',\n",
       " 'AppleCedarRust4.JPG',\n",
       " 'AppleScab1.JPG',\n",
       " 'AppleScab2.JPG',\n",
       " 'AppleScab3.JPG',\n",
       " 'CornCommonRust1.JPG',\n",
       " 'CornCommonRust2.JPG',\n",
       " 'CornCommonRust3.JPG',\n",
       " 'PotatoEarlyBlight1.JPG',\n",
       " 'PotatoEarlyBlight2.JPG',\n",
       " 'PotatoEarlyBlight3.JPG',\n",
       " 'PotatoEarlyBlight4.JPG',\n",
       " 'PotatoEarlyBlight5.JPG',\n",
       " 'PotatoHealthy1.JPG',\n",
       " 'PotatoHealthy2.JPG',\n",
       " 'TomatoEarlyBlight1.JPG',\n",
       " 'TomatoEarlyBlight2.JPG',\n",
       " 'TomatoEarlyBlight3.JPG',\n",
       " 'TomatoEarlyBlight4.JPG',\n",
       " 'TomatoEarlyBlight5.JPG',\n",
       " 'TomatoEarlyBlight6.JPG',\n",
       " 'TomatoHealthy1.JPG',\n",
       " 'TomatoHealthy2.JPG',\n",
       " 'TomatoHealthy3.JPG',\n",
       " 'TomatoHealthy4.JPG',\n",
       " 'TomatoYellowCurlVirus1.JPG',\n",
       " 'TomatoYellowCurlVirus2.JPG',\n",
       " 'TomatoYellowCurlVirus3.JPG',\n",
       " 'TomatoYellowCurlVirus4.JPG',\n",
       " 'TomatoYellowCurlVirus5.JPG',\n",
       " 'TomatoYellowCurlVirus6.JPG']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images = sorted(os.listdir(test_dir + '/test')) # since images in test folder are in alphabetical order\n",
    "test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:18.277682Z",
     "iopub.status.busy": "2020-12-15T07:16:18.275745Z",
     "iopub.status.idle": "2020-12-15T07:16:18.278376Z",
     "shell.execute_reply": "2020-12-15T07:16:18.278875Z"
    },
    "papermill": {
     "duration": 0.17446,
     "end_time": "2020-12-15T07:16:18.278995",
     "exception": false,
     "start_time": "2020-12-15T07:16:18.104535",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_image(img, model):\n",
    "    \"\"\"Converts image to array and return the predicted class\n",
    "        with highest probability\"\"\"\n",
    "    # Convert to a batch of 1\n",
    "    xb = to_device(img.unsqueeze(0), device)\n",
    "    # Get predictions from model\n",
    "    yb = model(xb)\n",
    "    # Pick index with highest probability\n",
    "    _, preds  = torch.max(yb, dim=1)\n",
    "    # Retrieve the class label\n",
    "\n",
    "    return train.classes[preds[0].item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:19.123586Z",
     "iopub.status.busy": "2020-12-15T07:16:19.122676Z",
     "iopub.status.idle": "2020-12-15T07:16:19.565853Z",
     "shell.execute_reply": "2020-12-15T07:16:19.566653Z"
    },
    "papermill": {
     "duration": 0.612956,
     "end_time": "2020-12-15T07:16:19.566789",
     "exception": false,
     "start_time": "2020-12-15T07:16:18.953833",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: AppleCedarRust1.JPG , Predicted: Apple___Cedar_apple_rust\n",
      "Label: AppleCedarRust2.JPG , Predicted: Apple___Cedar_apple_rust\n",
      "Label: AppleCedarRust3.JPG , Predicted: Apple___Cedar_apple_rust\n",
      "Label: AppleCedarRust4.JPG , Predicted: Apple___Cedar_apple_rust\n",
      "Label: AppleScab1.JPG , Predicted: Apple___Apple_scab\n",
      "Label: AppleScab2.JPG , Predicted: Apple___Apple_scab\n",
      "Label: AppleScab3.JPG , Predicted: Apple___Apple_scab\n",
      "Label: CornCommonRust1.JPG , Predicted: Corn_(maize)___Common_rust_\n",
      "Label: CornCommonRust2.JPG , Predicted: Corn_(maize)___Common_rust_\n",
      "Label: CornCommonRust3.JPG , Predicted: Corn_(maize)___Common_rust_\n",
      "Label: PotatoEarlyBlight1.JPG , Predicted: Potato___Early_blight\n",
      "Label: PotatoEarlyBlight2.JPG , Predicted: Potato___Early_blight\n",
      "Label: PotatoEarlyBlight3.JPG , Predicted: Potato___Early_blight\n",
      "Label: PotatoEarlyBlight4.JPG , Predicted: Potato___Early_blight\n",
      "Label: PotatoEarlyBlight5.JPG , Predicted: Potato___Early_blight\n",
      "Label: PotatoHealthy1.JPG , Predicted: Potato___healthy\n",
      "Label: PotatoHealthy2.JPG , Predicted: Potato___healthy\n",
      "Label: TomatoEarlyBlight1.JPG , Predicted: Tomato___Early_blight\n",
      "Label: TomatoEarlyBlight2.JPG , Predicted: Tomato___Early_blight\n",
      "Label: TomatoEarlyBlight3.JPG , Predicted: Tomato___Early_blight\n",
      "Label: TomatoEarlyBlight4.JPG , Predicted: Tomato___Early_blight\n",
      "Label: TomatoEarlyBlight5.JPG , Predicted: Tomato___Early_blight\n",
      "Label: TomatoEarlyBlight6.JPG , Predicted: Tomato___Early_blight\n",
      "Label: TomatoHealthy1.JPG , Predicted: Tomato___healthy\n",
      "Label: TomatoHealthy2.JPG , Predicted: Tomato___healthy\n",
      "Label: TomatoHealthy3.JPG , Predicted: Tomato___healthy\n",
      "Label: TomatoHealthy4.JPG , Predicted: Tomato___healthy\n",
      "Label: TomatoYellowCurlVirus1.JPG , Predicted: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Label: TomatoYellowCurlVirus2.JPG , Predicted: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Label: TomatoYellowCurlVirus3.JPG , Predicted: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Label: TomatoYellowCurlVirus4.JPG , Predicted: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Label: TomatoYellowCurlVirus5.JPG , Predicted: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n",
      "Label: TomatoYellowCurlVirus6.JPG , Predicted: Tomato___Tomato_Yellow_Leaf_Curl_Virus\n"
     ]
    }
   ],
   "source": [
    "# getting all predictions (actual label vs predicted)\n",
    "for i, (img, label) in enumerate(test):\n",
    "    print('Label:', test_images[i], ', Predicted:', predict_image(img, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.167812,
     "end_time": "2020-12-15T07:16:20.231512",
     "exception": false,
     "start_time": "2020-12-15T07:16:20.063700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.163261,
     "end_time": "2020-12-15T07:16:20.562790",
     "exception": false,
     "start_time": "2020-12-15T07:16:20.399529",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**There are several ways to save the model in Pytorch, following are the two most common ways**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:21.236912Z",
     "iopub.status.busy": "2020-12-15T07:16:21.236137Z",
     "iopub.status.idle": "2020-12-15T07:16:21.302803Z",
     "shell.execute_reply": "2020-12-15T07:16:21.302251Z"
    },
    "papermill": {
     "duration": 0.241697,
     "end_time": "2020-12-15T07:16:21.302920",
     "exception": false,
     "start_time": "2020-12-15T07:16:21.061223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving to the kaggle working directory\n",
    "PATH = './plant-disease-model.pth'  \n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-15T07:16:21.979277Z",
     "iopub.status.busy": "2020-12-15T07:16:21.973670Z",
     "iopub.status.idle": "2020-12-15T07:16:22.039546Z",
     "shell.execute_reply": "2020-12-15T07:16:22.038875Z"
    },
    "papermill": {
     "duration": 0.236439,
     "end_time": "2020-12-15T07:16:22.039674",
     "exception": false,
     "start_time": "2020-12-15T07:16:21.803235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# saving the entire model to working directory\n",
    "PATH = './plant-disease-model-complete.pth'\n",
    "torch.save(model, PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "papermill": {
   "duration": 1424.697889,
   "end_time": "2020-12-15T07:16:24.493770",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-12-15T06:52:39.795881",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
